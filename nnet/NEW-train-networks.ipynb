{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks\n",
    "\n",
    "This notebook describes the workflow for training neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from dstools.reproducibility import make_filename\n",
    "\n",
    "from yass import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YASS version is: fe1bd86 updates detect.run to use new separated code\n"
     ]
    }
   ],
   "source": [
    "# for reference\n",
    "print('YASS version is: {}'.format(util.get_version()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = Path('~', 'data').expanduser()\n",
    "path_to_models = Path(path_to_data, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sets = Path(path_to_data, 'training-sets')\n",
    "\n",
    "path_to_x = Path(path_to_sets, 'x-triage-31wf7ch-15-Aug-2018@00-14-33.npy')\n",
    "path_to_y = Path(path_to_sets, 'y-triage-31wf7ch-15-Aug-2018@00-14-33.npy')\n",
    "\n",
    "x_triage = np.load(path_to_x)\n",
    "y_triage = np.load(path_to_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x_train, input_shape):\n",
    "    n_data, window_size, n_channels, _ = x_train.shape\n",
    "\n",
    "    model = Sequential()\n",
    "        \n",
    "#     model.add(MaxPooling2D(pool_size=(2, 1), data_format=\"channels_last\", padding='same'))\n",
    "    \n",
    "#     model.add(Dropout(0.75))\n",
    "\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     padding='same', activation='relu', use_bias=True,\n",
    "                     data_format=\"channels_last\", input_shape=input_shape))\n",
    "\n",
    "\n",
    "#     model.add(Conv2D(70, kernel_size=(window_size, 1),\n",
    "#                      padding='valid', activation='relu', use_bias=True,\n",
    "#                      data_format=\"channels_last\"))\n",
    "    \n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     padding='same', activation='relu', use_bias=True,\n",
    "                     data_format=\"channels_last\"))\n",
    "\n",
    "\n",
    "#     model.add(Conv2D(70, kernel_size=(1, n_channels),\n",
    "#                      padding='valid', activation='relu', use_bias=True,\n",
    "#                      data_format=\"channels_last\"))\n",
    "    \n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     padding='same', activation='linear', use_bias=True,\n",
    "                     data_format=\"channels_last\"))\n",
    "        \n",
    "#     model.add(MaxPooling2D(pool_size=(1, 2), data_format=\"channels_last\", padding='same'))\n",
    "#     model.add(Dropout(0.75))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    opt = keras.optimizers.adam(lr=0.001)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triage Ttaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 31, 7, 10)         260       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 31, 7, 10)         2510      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 31, 7, 10)         2510      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2170)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2171      \n",
      "=================================================================\n",
      "Total params: 7,451\n",
      "Trainable params: 7,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import models\n",
    "x = x_triage[:, : , :, np.newaxis]\n",
    "\n",
    "(x_train, x_test,\n",
    "y_train, y_test) = train_test_split(x, y_triage, test_size=0.3)\n",
    "\n",
    "_, wf, ch, _ = x_train.shape\n",
    "\n",
    "m = make_model(x, (wf, ch, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28224 samples, validate on 12096 samples\n",
      "Epoch 1/100\n",
      "28224/28224 [==============================] - 1s 30us/step - loss: 0.1639 - acc: 0.9378 - val_loss: 0.1604 - val_acc: 0.9353\n",
      "Epoch 2/100\n",
      "28224/28224 [==============================] - 1s 27us/step - loss: 0.1646 - acc: 0.9363 - val_loss: 0.1581 - val_acc: 0.9365\n",
      "Epoch 3/100\n",
      "28224/28224 [==============================] - 1s 27us/step - loss: 0.1614 - acc: 0.9386 - val_loss: 0.1547 - val_acc: 0.9383\n",
      "Epoch 4/100\n",
      "28224/28224 [==============================] - 1s 27us/step - loss: 0.1610 - acc: 0.9379 - val_loss: 0.1538 - val_acc: 0.9403\n",
      "Epoch 5/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1572 - acc: 0.9401 - val_loss: 0.1560 - val_acc: 0.9396\n",
      "Epoch 6/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1571 - acc: 0.9398 - val_loss: 0.1508 - val_acc: 0.9411\n",
      "Epoch 7/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1541 - acc: 0.9412 - val_loss: 0.1496 - val_acc: 0.9408\n",
      "Epoch 8/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1524 - acc: 0.9420 - val_loss: 0.1488 - val_acc: 0.9406\n",
      "Epoch 9/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1512 - acc: 0.9426 - val_loss: 0.1461 - val_acc: 0.9425\n",
      "Epoch 10/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1493 - acc: 0.9433 - val_loss: 0.1465 - val_acc: 0.9403\n",
      "Epoch 11/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1490 - acc: 0.9437 - val_loss: 0.1453 - val_acc: 0.9412\n",
      "Epoch 12/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1486 - acc: 0.9422 - val_loss: 0.1430 - val_acc: 0.9448\n",
      "Epoch 13/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1466 - acc: 0.9444 - val_loss: 0.1457 - val_acc: 0.9435\n",
      "Epoch 14/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1456 - acc: 0.9453 - val_loss: 0.1418 - val_acc: 0.9452\n",
      "Epoch 15/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1437 - acc: 0.9457 - val_loss: 0.1402 - val_acc: 0.9454\n",
      "Epoch 16/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1427 - acc: 0.9459 - val_loss: 0.1386 - val_acc: 0.9462\n",
      "Epoch 17/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1429 - acc: 0.9459 - val_loss: 0.1381 - val_acc: 0.9458\n",
      "Epoch 18/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1411 - acc: 0.9462 - val_loss: 0.1375 - val_acc: 0.9458\n",
      "Epoch 19/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1396 - acc: 0.9467 - val_loss: 0.1360 - val_acc: 0.9467\n",
      "Epoch 20/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1383 - acc: 0.9468 - val_loss: 0.1357 - val_acc: 0.9466\n",
      "Epoch 21/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1376 - acc: 0.9471 - val_loss: 0.1341 - val_acc: 0.9473\n",
      "Epoch 22/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1363 - acc: 0.9475 - val_loss: 0.1365 - val_acc: 0.9476\n",
      "Epoch 23/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1362 - acc: 0.9482 - val_loss: 0.1337 - val_acc: 0.9485\n",
      "Epoch 24/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1348 - acc: 0.9486 - val_loss: 0.1347 - val_acc: 0.9480\n",
      "Epoch 25/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1347 - acc: 0.9487 - val_loss: 0.1320 - val_acc: 0.9487\n",
      "Epoch 26/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1329 - acc: 0.9494 - val_loss: 0.1310 - val_acc: 0.9492\n",
      "Epoch 27/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1317 - acc: 0.9497 - val_loss: 0.1297 - val_acc: 0.9498\n",
      "Epoch 28/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1311 - acc: 0.9497 - val_loss: 0.1291 - val_acc: 0.9497\n",
      "Epoch 29/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1302 - acc: 0.9501 - val_loss: 0.1290 - val_acc: 0.9489\n",
      "Epoch 30/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1304 - acc: 0.9493 - val_loss: 0.1281 - val_acc: 0.9494\n",
      "Epoch 31/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1295 - acc: 0.9501 - val_loss: 0.1289 - val_acc: 0.9481\n",
      "Epoch 32/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1290 - acc: 0.9503 - val_loss: 0.1267 - val_acc: 0.9511\n",
      "Epoch 33/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1275 - acc: 0.9506 - val_loss: 0.1260 - val_acc: 0.9516\n",
      "Epoch 34/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1271 - acc: 0.9504 - val_loss: 0.1254 - val_acc: 0.9514\n",
      "Epoch 35/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1262 - acc: 0.9515 - val_loss: 0.1248 - val_acc: 0.9516\n",
      "Epoch 36/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1256 - acc: 0.9517 - val_loss: 0.1260 - val_acc: 0.9496\n",
      "Epoch 37/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1260 - acc: 0.9517 - val_loss: 0.1260 - val_acc: 0.9492\n",
      "Epoch 38/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1260 - acc: 0.9511 - val_loss: 0.1281 - val_acc: 0.9480\n",
      "Epoch 39/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1267 - acc: 0.9511 - val_loss: 0.1269 - val_acc: 0.9485\n",
      "Epoch 40/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1291 - acc: 0.9497 - val_loss: 0.1373 - val_acc: 0.9439\n",
      "Epoch 41/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1384 - acc: 0.9437 - val_loss: 0.1418 - val_acc: 0.9431\n",
      "Epoch 42/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1402 - acc: 0.9432 - val_loss: 0.1227 - val_acc: 0.9530\n",
      "Epoch 43/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1259 - acc: 0.9515 - val_loss: 0.1323 - val_acc: 0.9477\n",
      "Epoch 44/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1272 - acc: 0.9514 - val_loss: 0.1215 - val_acc: 0.9533\n",
      "Epoch 45/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1270 - acc: 0.9509 - val_loss: 0.1276 - val_acc: 0.9473\n",
      "Epoch 46/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1266 - acc: 0.9512 - val_loss: 0.1260 - val_acc: 0.9491\n",
      "Epoch 47/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1238 - acc: 0.9520 - val_loss: 0.1200 - val_acc: 0.9536\n",
      "Epoch 48/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1209 - acc: 0.9530 - val_loss: 0.1272 - val_acc: 0.9511\n",
      "Epoch 49/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1211 - acc: 0.9547 - val_loss: 0.1205 - val_acc: 0.9525\n",
      "Epoch 50/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1194 - acc: 0.9547 - val_loss: 0.1190 - val_acc: 0.9545\n",
      "Epoch 51/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1191 - acc: 0.9540 - val_loss: 0.1202 - val_acc: 0.9538\n",
      "Epoch 52/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1182 - acc: 0.9548 - val_loss: 0.1178 - val_acc: 0.9544\n",
      "Epoch 53/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1171 - acc: 0.9557 - val_loss: 0.1174 - val_acc: 0.9545\n",
      "Epoch 54/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1166 - acc: 0.9555 - val_loss: 0.1175 - val_acc: 0.9543\n",
      "Epoch 55/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1165 - acc: 0.9559 - val_loss: 0.1169 - val_acc: 0.9543\n",
      "Epoch 56/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1164 - acc: 0.9550 - val_loss: 0.1214 - val_acc: 0.9535\n",
      "Epoch 57/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1181 - acc: 0.9553 - val_loss: 0.1167 - val_acc: 0.9547\n",
      "Epoch 58/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1157 - acc: 0.9557 - val_loss: 0.1171 - val_acc: 0.9540\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1159 - acc: 0.9554 - val_loss: 0.1168 - val_acc: 0.9540\n",
      "Epoch 60/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1152 - acc: 0.9554 - val_loss: 0.1152 - val_acc: 0.9545\n",
      "Epoch 61/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1154 - acc: 0.9560 - val_loss: 0.1147 - val_acc: 0.9550\n",
      "Epoch 62/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1139 - acc: 0.9561 - val_loss: 0.1151 - val_acc: 0.9552\n",
      "Epoch 63/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1133 - acc: 0.9568 - val_loss: 0.1150 - val_acc: 0.9555\n",
      "Epoch 64/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1134 - acc: 0.9565 - val_loss: 0.1146 - val_acc: 0.9546\n",
      "Epoch 65/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1147 - acc: 0.9559 - val_loss: 0.1141 - val_acc: 0.9544\n",
      "Epoch 66/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1130 - acc: 0.9571 - val_loss: 0.1135 - val_acc: 0.9550\n",
      "Epoch 67/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1122 - acc: 0.9575 - val_loss: 0.1134 - val_acc: 0.9550\n",
      "Epoch 68/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1117 - acc: 0.9575 - val_loss: 0.1139 - val_acc: 0.9550\n",
      "Epoch 69/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1115 - acc: 0.9575 - val_loss: 0.1126 - val_acc: 0.9564\n",
      "Epoch 70/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1105 - acc: 0.9576 - val_loss: 0.1123 - val_acc: 0.9563\n",
      "Epoch 71/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1100 - acc: 0.9577 - val_loss: 0.1120 - val_acc: 0.9561\n",
      "Epoch 72/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1095 - acc: 0.9579 - val_loss: 0.1125 - val_acc: 0.9568\n",
      "Epoch 73/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1099 - acc: 0.9576 - val_loss: 0.1116 - val_acc: 0.9563\n",
      "Epoch 74/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1096 - acc: 0.9575 - val_loss: 0.1135 - val_acc: 0.9551\n",
      "Epoch 75/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1102 - acc: 0.9575 - val_loss: 0.1119 - val_acc: 0.9556\n",
      "Epoch 76/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1095 - acc: 0.9579 - val_loss: 0.1109 - val_acc: 0.9570\n",
      "Epoch 77/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1083 - acc: 0.9579 - val_loss: 0.1113 - val_acc: 0.9578\n",
      "Epoch 78/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1088 - acc: 0.9576 - val_loss: 0.1118 - val_acc: 0.9569\n",
      "Epoch 79/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1074 - acc: 0.9588 - val_loss: 0.1101 - val_acc: 0.9568\n",
      "Epoch 80/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1080 - acc: 0.9584 - val_loss: 0.1132 - val_acc: 0.9553\n",
      "Epoch 81/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1096 - acc: 0.9580 - val_loss: 0.1161 - val_acc: 0.9540\n",
      "Epoch 82/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1124 - acc: 0.9565 - val_loss: 0.1121 - val_acc: 0.9560\n",
      "Epoch 83/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1087 - acc: 0.9574 - val_loss: 0.1145 - val_acc: 0.9541\n",
      "Epoch 84/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1103 - acc: 0.9568 - val_loss: 0.1151 - val_acc: 0.9535\n",
      "Epoch 85/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1088 - acc: 0.9582 - val_loss: 0.1097 - val_acc: 0.9570\n",
      "Epoch 86/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1072 - acc: 0.9591 - val_loss: 0.1096 - val_acc: 0.9568\n",
      "Epoch 87/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1052 - acc: 0.9593 - val_loss: 0.1086 - val_acc: 0.9582\n",
      "Epoch 88/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1050 - acc: 0.9594 - val_loss: 0.1110 - val_acc: 0.9563\n",
      "Epoch 89/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1053 - acc: 0.9598 - val_loss: 0.1083 - val_acc: 0.9578\n",
      "Epoch 90/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1047 - acc: 0.9595 - val_loss: 0.1092 - val_acc: 0.9568\n",
      "Epoch 91/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1042 - acc: 0.9600 - val_loss: 0.1075 - val_acc: 0.9580\n",
      "Epoch 92/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1035 - acc: 0.9599 - val_loss: 0.1076 - val_acc: 0.9582\n",
      "Epoch 93/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1033 - acc: 0.9601 - val_loss: 0.1086 - val_acc: 0.9572\n",
      "Epoch 94/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1034 - acc: 0.9601 - val_loss: 0.1070 - val_acc: 0.9584\n",
      "Epoch 95/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1024 - acc: 0.9605 - val_loss: 0.1070 - val_acc: 0.9578\n",
      "Epoch 96/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1024 - acc: 0.9604 - val_loss: 0.1066 - val_acc: 0.9584\n",
      "Epoch 97/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1019 - acc: 0.9606 - val_loss: 0.1077 - val_acc: 0.9573\n",
      "Epoch 98/100\n",
      "28224/28224 [==============================] - 1s 25us/step - loss: 0.1022 - acc: 0.9603 - val_loss: 0.1081 - val_acc: 0.9570\n",
      "Epoch 99/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1023 - acc: 0.9609 - val_loss: 0.1081 - val_acc: 0.9571\n",
      "Epoch 100/100\n",
      "28224/28224 [==============================] - 1s 26us/step - loss: 0.1027 - acc: 0.9603 - val_loss: 0.1061 - val_acc: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a9408ceb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train,\n",
    "          batch_size=10000, epochs=100, shuffle=True,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triage-31wf7ch-15-Aug-2018@00-17-16.h5\n",
      "triage-31wf7ch-15-Aug-2018@00-17-16.yaml\n"
     ]
    }
   ],
   "source": [
    "_, wf, ch, _ = m.input_shape\n",
    "\n",
    "prefix = f'triage-{wf}wf{ch}ch-'\n",
    "name_model, name_metadata = make_filename(prefix=prefix, extension=('h5', 'yaml'))\n",
    "print(name_model)\n",
    "print(name_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = Path(path_to_models, name_model)\n",
    "path_to_metadata = Path(path_to_models, name_metadata)\n",
    "\n",
    "m.save(path_to_model)\n",
    "\n",
    "metadata = {'path_to_x': str(path_to_x), 'path_to_y': str(path_to_x), 'input_shape': list(m.input_shape)}\n",
    "\n",
    "with open(path_to_metadata, 'w') as f:\n",
    "    yaml.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
