{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks\n",
    "\n",
    "This notebook describes the workflow for training neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from dstools.reproducibility import make_filename\n",
    "from dstools.reproducibility.util import git_hash_in_path, get_version\n",
    "from dstools.util import save\n",
    "\n",
    "from yass import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "here = getcwd()\n",
    "here_version = git_hash_in_path(here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YASS version is: 9220361 fixes make spikes function\n",
      "nbs version is: a786da4 Merge branch 'master' of https://github.com/edublancas/yass-private\n"
     ]
    }
   ],
   "source": [
    "# for reference\n",
    "print('YASS version is: {}'.format(get_version('yass')))\n",
    "print('nbs version is: {}'.format(here_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = Path('~', 'data', 'detect').expanduser()\n",
    "path_to_output = path_to_data  / 'models'\n",
    "path_to_set = path_to_data / 'training-set.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.load(path_to_set)\n",
    "\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x_train, input_shape):\n",
    "    n_data, window_size, n_channels, _ = x_train.shape\n",
    "\n",
    "    model = Sequential()\n",
    "        \n",
    "#     model.add(MaxPooling2D(pool_size=(2, 1), data_format=\"channels_last\", padding='same'))\n",
    "    \n",
    "#     model.add(Dropout(0.75))\n",
    "\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     padding='same', activation='relu', use_bias=True,\n",
    "                     data_format=\"channels_last\", input_shape=input_shape))\n",
    "\n",
    "\n",
    "#     model.add(Conv2D(70, kernel_size=(window_size, 1),\n",
    "#                      padding='valid', activation='relu', use_bias=True,\n",
    "#                      data_format=\"channels_last\"))\n",
    "    \n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     padding='same', activation='relu', use_bias=True,\n",
    "                     data_format=\"channels_last\"))\n",
    "\n",
    "\n",
    "#     model.add(Conv2D(70, kernel_size=(1, n_channels),\n",
    "#                      padding='valid', activation='relu', use_bias=True,\n",
    "#                      data_format=\"channels_last\"))\n",
    "    \n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     padding='same', activation='linear', use_bias=True,\n",
    "                     data_format=\"channels_last\"))\n",
    "        \n",
    "#     model.add(MaxPooling2D(pool_size=(1, 2), data_format=\"channels_last\", padding='same'))\n",
    "#     model.add(Dropout(0.75))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # initiate RMSprop optimizer\n",
    "    opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "    opt = keras.optimizers.adam(lr=0.001)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 61, 7, 10)         260       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 7, 10)         2510      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 61, 7, 10)         2510      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4270)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4271      \n",
      "=================================================================\n",
      "Total params: 9,551\n",
      "Trainable params: 9,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import models\n",
    "x_train = x_train[:, : , :, np.newaxis]\n",
    "x_test = x_test[:, : , :, np.newaxis]\n",
    "\n",
    "_, wf, ch, _ = x_train.shape\n",
    "\n",
    "m = make_model(x_train, (wf, ch, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36984 samples, validate on 18216 samples\n",
      "Epoch 1/100\n",
      "36984/36984 [==============================] - 3s 86us/step - loss: 0.1179 - acc: 0.9626 - val_loss: 0.0177 - val_acc: 0.9954\n",
      "Epoch 2/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0137 - acc: 0.9965 - val_loss: 0.0141 - val_acc: 0.9959\n",
      "Epoch 3/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0100 - acc: 0.9975 - val_loss: 0.0104 - val_acc: 0.9971\n",
      "Epoch 4/100\n",
      "36984/36984 [==============================] - 2s 59us/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.0100 - val_acc: 0.9973\n",
      "Epoch 5/100\n",
      "36984/36984 [==============================] - 2s 59us/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0068 - val_acc: 0.9979\n",
      "Epoch 6/100\n",
      "36984/36984 [==============================] - 2s 59us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0064 - val_acc: 0.9980\n",
      "Epoch 7/100\n",
      "36984/36984 [==============================] - 2s 59us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 8/100\n",
      "36984/36984 [==============================] - 2s 59us/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0052 - val_acc: 0.9985\n",
      "Epoch 9/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0044 - val_acc: 0.9983\n",
      "Epoch 10/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0051 - val_acc: 0.9986\n",
      "Epoch 11/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0044 - val_acc: 0.9987\n",
      "Epoch 12/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0041 - val_acc: 0.9989\n",
      "Epoch 13/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0054 - val_acc: 0.9985\n",
      "Epoch 14/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0044 - val_acc: 0.9987\n",
      "Epoch 15/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0043 - val_acc: 0.9988\n",
      "Epoch 16/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0035 - val_acc: 0.9990\n",
      "Epoch 17/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0034 - val_acc: 0.9990\n",
      "Epoch 18/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0038 - val_acc: 0.9989\n",
      "Epoch 19/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0038 - val_acc: 0.9989\n",
      "Epoch 20/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Epoch 21/100\n",
      "36984/36984 [==============================] - 2s 57us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0037 - val_acc: 0.9990\n",
      "Epoch 22/100\n",
      "36984/36984 [==============================] - 2s 58us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0039 - val_acc: 0.9990\n",
      "Epoch 23/100\n",
      "36984/36984 [==============================] - 2s 57us/step - loss: 8.5972e-04 - acc: 0.9998 - val_loss: 0.0041 - val_acc: 0.9990\n",
      "Epoch 24/100\n",
      "17000/36984 [============>.................] - ETA: 0s - loss: 5.4327e-04 - acc: 0.9999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-de4780858e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m m.fit(x_train, y_train,\n\u001b[1;32m      2\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/yass/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/yass/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yass/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yass/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/yass/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit(x_train, y_train,\n",
    "      batch_size=1000, epochs=100, shuffle=True,\n",
    "      validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path_to_set': PosixPath('/home/Edu/data/detect/training-set.npz'),\n",
       " 'yass_version': '9220361 fixes make spikes function',\n",
       " 'nb_version': \"a786da4 Merge branch 'master' of https://github.com/edublancas/yass-private\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = dict(path_to_set=path_to_set,\n",
    "                yass_version=get_version('yass'),\n",
    "                nb_version=git_hash_in_path(getcwd()))\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, wf, ch, _ = m.input_shape\n",
    "\n",
    "sufix = f'detect-{wf}wf{ch}ch'\n",
    "names = make_filename(sufix=sufix, extension=('h5', 'yaml'))\n",
    "\n",
    "path_to_model, path_to_metadata = [str(path_to_output / name) for name in names]\n",
    "\n",
    "m.save(path_to_model)\n",
    "save(metadata, path_to_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Edu/data/detect/models/2018-10-03T04-13-50:detect-61wf7ch.h5\n"
     ]
    }
   ],
   "source": [
    "print(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
