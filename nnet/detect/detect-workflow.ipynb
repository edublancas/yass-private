{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector network workflow\n",
    "\n",
    "Tested with Python 3.6.7 (from miniconda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install numpy seaborn sklearn-evaluation tensorflow\n",
    "pip install git+git://github.com/edublancas/dstools\n",
    "pip install git+git://github.com/paninski-lab/yass@8ddce299fe52901af0b35f3a49dda86f61ca2c6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p /tmp/spike-sorting\n",
    "curl https://dl.dropboxusercontent.com/s/sylnygjmcvkmi4z/templates.npy?dl=0 -o /tmp/spike-sorting/templates.npy\n",
    "curl https://dl.dropboxusercontent.com/s/smk83ob73y9z7p0/config.yaml?dl=0 -o /tmp/spike-sorting/config.yaml\n",
    "curl https://dl.dropboxusercontent.com/s/mfp5vcu9b53ws91/noise_cov.npz?dl=0 -o /tmp/spike-sorting/noise_cov.npz\n",
    "curl https://dl.dropboxusercontent.com/s/k9qa7vttuzrsmr4/geometry.txt?dl=0 -o /tmp/spike-sorting/geometry.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Train/Test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from os.path import expanduser\n",
    "from os import path\n",
    "\n",
    "import yass\n",
    "from yass import read_config\n",
    "from yass.augment import make\n",
    "from yass.neuralnetwork import NeuralNetDetector\n",
    "from yass.batch import RecordingsReader\n",
    "from yass.augment.noise import noise_cov\n",
    "from yass.templates import TemplatesProcessor\n",
    "from yass.geometry import make_channel_index\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from dstools import plot\n",
    "import sklearn_evaluation.plot as skplot\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = expanduser('~/data')\n",
    "path_to_experiment = path.join(path_to_data, 'retinal/sample_output')\n",
    "path_to_standarized = path.join(path_to_experiment,\n",
    "                                'preprocess', 'standarized.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yass.set_config('/tmp/spike-sorting/config.yaml',\n",
    "                '/tmp/spike-sorting/output')\n",
    "CONFIG = read_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_templates = np.load('/tmp/spike-sorting/templates.npy')\n",
    "n_templates, waveform_length, _ = raw_templates.shape\n",
    "print(raw_templates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop templates spatially\n",
    "processor = TemplatesProcessor(raw_templates)\n",
    "templates = (processor\n",
    "            .crop_spatially(CONFIG.neigh_channels, CONFIG.geom)\n",
    "            .values)\n",
    "templates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot.grid_from_array(templates, axis=0, auto_figsize=4,\n",
    "                     max_cols=3, elements=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Estimating noise covariance structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_idx = make_channel_index(CONFIG.neigh_channels, CONFIG.geom)\n",
    "selected_channels = ch_idx[0]\n",
    "selected_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_NOISE_COV = True\n",
    "\n",
    "\n",
    "if LOAD_NOISE_COV:\n",
    "    cov = np.load('/tmp/spike-sorting/noise_cov.npz')\n",
    "    spatial_sig, temporal_sig = cov['spatial_sig'], cov['temporal_sig']\n",
    "else:\n",
    "    rec = RecordingsReader(path_to_standarized, loader='array').data[:, selected_channels]\n",
    "    (spatial_sig,\n",
    "     temporal_sig) = noise_cov(rec, templates.shape[1], templates.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amplitude = 4\n",
    "max_amplitude = 60\n",
    "n_clean_per_template = 200\n",
    "n_positive_total = n_templates *  n_clean_per_template\n",
    "n_collided_per_spike = 0\n",
    "probs = [0.6, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make.training_data_detect(templates=templates,\n",
    "                                 minimum_amplitude=min_amplitude,\n",
    "                                 maximum_amplitude=max_amplitude,\n",
    "                                 n_clean_per_template=n_clean_per_template,\n",
    "                                 n_collided_per_spike=n_collided_per_spike,\n",
    "                                 n_temporally_misaligned_per_spike=0.25,\n",
    "                                 n_noise=int(n_positive_total * 0.5),\n",
    "                                 n_spatially_misaliged_per_spike=0,\n",
    "                                 spatial_SIG=spatial_sig,\n",
    "                                 temporal_SIG=temporal_sig,\n",
    "                                 add_noise_kwargs={'reject_cancelling_noise': False},\n",
    "                                 from_templates_kwargs={'probabilities': probs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[y == 1].shape, X[y == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Plot some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive examples (spikes)\n",
    "plot.grid_from_array(X[y == 1], axis=0,\n",
    "                     elements=9, auto_figsize=3,\n",
    "                     sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative examples: noise and non-centered spikes\n",
    "plot.grid_from_array(X[y == 0], axis=0,\n",
    "                     elements=9, auto_figsize=3,\n",
    "                     sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 5000\n",
    "n_batch = 512\n",
    "l2_reg_scale = 0.00000005\n",
    "train_step_size =  0.0001\n",
    "filters_detect = [32, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, waveform_length, n_neighbors =  X.shape\n",
    "\n",
    "detector = NeuralNetDetector('/tmp/spike-sorting/my-detector-network.ckpt', filters_detect,\n",
    "                             waveform_length, n_neighbors,\n",
    "                             threshold=0.5,\n",
    "                             channel_index=CONFIG.channel_index,\n",
    "                             n_iter=n_iter)\n",
    "\n",
    "detector.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Network evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detector.predict(detector.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplot.confusion_matrix(detector.y_test, preds, normalize=True, target_names=['Noise', 'Spike'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /tmp/spike-sorting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
